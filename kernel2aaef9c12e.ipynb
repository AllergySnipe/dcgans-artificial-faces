{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom keras.layers import Dense,Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape,Activation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 32\nRANDOM_SEED=100\nDATA_PATH = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/'\nEPOCHS = 20\nBUFFER_SIZE = 60000\nBATCH_SIZE = 128\n\nPREVIEW_ROWS = 4\nPREVIEW_COLS = 7\nPREVIEW_MARGIN = 16\n\ntraining_data=[]\nfor dirname, _, filenames in os.walk(DATA_PATH):\n    for filename in filenames:\n        training_data.append(DATA_PATH+filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_data[:10])\nlen(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=[]\nfor path in training_data[:50000]:\n    image=Image.open(path).resize((IMG_SIZE, IMG_SIZE))\n    images.append(np.asarray(image))\nimages = np.reshape(images,(-1,IMG_SIZE,\n            IMG_SIZE,3))\nimages = images.astype(np.float32)\nimages = (images - 127.5) / 127.5 \nprint(images[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    \n    model.add(Dense(4*4*512,input_shape=(RANDOM_SEED,)))\n    model.add(Reshape((4,4,512)))\n    \n    model.add(Conv2DTranspose(256,kernel_size=4,padding=\"same\",strides=2))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    \n    model.add(Conv2DTranspose(128,kernel_size=4,padding=\"same\",strides=2))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    \n    model.add(Conv2DTranspose(3,kernel_size=4,padding=\"same\",strides=2))\n    model.add(Activation(\"tanh\"))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    \n    model.add(Conv2D(32,kernel_size=4, strides=2, padding=\"same\",input_shape=[IMG_SIZE, IMG_SIZE, 3]))\n    model.add(LeakyReLU(0.2))\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(64,kernel_size=4, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(0.2))\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128,kernel_size=4, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(0.2))\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(256,kernel_size=4, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(0.2))\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    model.add(Dense(1,Activation(\"sigmoid\")))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator=make_generator_model()\ndiscriminator=make_discriminator_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_images(cnt,noise):\n  image_array = np.full(( \n      PREVIEW_MARGIN + (PREVIEW_ROWS * (IMG_SIZE+PREVIEW_MARGIN)), \n      PREVIEW_MARGIN + (PREVIEW_COLS * (IMG_SIZE+PREVIEW_MARGIN)), 3), \n      255, dtype=np.uint8)\n  \n  generated_images = generator.predict(noise)\n\n  generated_images = 0.5 * generated_images + 0.5\n\n  image_count = 0\n  for row in range(PREVIEW_ROWS):\n      for col in range(PREVIEW_COLS):\n        r = row * (IMG_SIZE+16) + PREVIEW_MARGIN\n        c = col * (IMG_SIZE+16) + PREVIEW_MARGIN\n        image_array[r:r+IMG_SIZE,c:c+IMG_SIZE] = generated_images[image_count] * 255\n        image_count += 1\n\n          \n  output_path = os.path.join(DATA_PATH,'output')\n  if not os.path.exists(output_path):\n    os.makedirs(output_path)\n  \n  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n  im = Image.fromarray(image_array)\n  im.save(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef get_generator_loss(generated_output):\n    return tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.ones_like(generated_output), logits = generated_output)\ndef get_discriminator_loss(generator_output, real_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(generator_output), generator_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.optimizers.Adam(1.5e-4)\ndiscriminator_optimizer = tf.optimizers.Adam(1.5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_step(images):\n    seed = tf.random.normal([BATCH_SIZE, RANDOM_SEED])\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        gen_images = generator(seed,training=True)\n        \n        real_output = discriminator(images,training=True)\n        fake_output = discriminator(gen_images,training=True)\n        \n        gen_loss = get_generator_loss(fake_output)\n        disc_loss = get_discriminator_loss(fake_output,real_output)\n        \n        grad_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n        grad_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n        \n        generator_optimizer.apply_gradients(zip(grad_of_generator,generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(grad_of_discriminator,discriminator.trainable_variables))\n        \n    return gen_loss,disc_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(images, epochs):\n    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, RANDOM_SEED))\n    for epoch in range(epochs):\n        gen_loss_list=[]\n        disc_loss_list=[]\n        for image in train_dataset:\n            t = train_step(image)\n            gen_loss_list.append(t[0])\n            disc_loss_list.append(t[1])\n        g_loss = sum(gen_loss_list)/len(gen_loss_list)\n        d_loss = sum(disc_loss_list)/len(disc_loss_list)\n        print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(train_dataset,EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}